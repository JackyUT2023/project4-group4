{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model Design (Original Attempt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are 2 sets of image data: </br>\n",
    "`Train_original` folder will have 4 folders and named as the shoes brand name. There are totally 10 images in each folder.</br>\n",
    "`Validation_original` folder have the same content as `Train_original` folder, and will be used to test the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Jacky Zhang\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 40 images belonging to 4 classes.\n",
      "Found 40 images belonging to 4 classes.\n",
      "WARNING:tensorflow:From c:\\Users\\Jacky Zhang\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Jacky Zhang\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Jacky Zhang\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\Jacky Zhang\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Jacky Zhang\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3978 - accuracy: 0.1250 - val_loss: 6.1504 - val_accuracy: 0.2812\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 2.4691 - accuracy: 0.2500 - val_loss: 7.8129 - val_accuracy: 0.2812\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 5.4315 - accuracy: 0.3750 - val_loss: 3.3111 - val_accuracy: 0.2812\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 3.3776 - accuracy: 0.2500 - val_loss: 1.6028 - val_accuracy: 0.2812\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 1.8636 - accuracy: 0.2500 - val_loss: 1.3697 - val_accuracy: 0.3750\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 1.4015 - accuracy: 0.2500 - val_loss: 1.4079 - val_accuracy: 0.2188\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 1s 668ms/step - loss: 1.4765 - accuracy: 0.1875 - val_loss: 1.3330 - val_accuracy: 0.2812\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 1.3397 - accuracy: 0.2500 - val_loss: 1.3194 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 1s 671ms/step - loss: 1.2992 - accuracy: 0.5625 - val_loss: 1.2751 - val_accuracy: 0.4375\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 1.2585 - accuracy: 0.4375 - val_loss: 1.1941 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 1.2857 - accuracy: 0.6250 - val_loss: 1.1640 - val_accuracy: 0.6562\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 1s 652ms/step - loss: 1.1774 - accuracy: 0.6250 - val_loss: 1.0941 - val_accuracy: 0.7188\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 1s 697ms/step - loss: 1.1042 - accuracy: 0.6875 - val_loss: 0.9607 - val_accuracy: 0.9062\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 1s 638ms/step - loss: 0.9824 - accuracy: 0.8438 - val_loss: 0.9396 - val_accuracy: 0.7188\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.9129 - accuracy: 0.8750 - val_loss: 0.9875 - val_accuracy: 0.5938\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 1s 652ms/step - loss: 0.8876 - accuracy: 0.6562 - val_loss: 0.7920 - val_accuracy: 0.6562\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 0.7783 - accuracy: 0.6875 - val_loss: 0.6777 - val_accuracy: 0.9062\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 1s 642ms/step - loss: 0.7026 - accuracy: 0.8438 - val_loss: 0.5745 - val_accuracy: 0.8750\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 1s 641ms/step - loss: 0.5565 - accuracy: 0.9062 - val_loss: 0.4216 - val_accuracy: 0.9688\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.4856 - accuracy: 1.0000 - val_loss: 0.5965 - val_accuracy: 0.7812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jacky Zhang\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 0.5452 - accuracy: 0.8250 - 226ms/epoch - 113ms/step\n",
      "\n",
      "Test accuracy: 0.824999988079071\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Define parameters\n",
    "input_shape = (150, 150, 3)  # Image dimensions\n",
    "num_classes = 4  # Nike, Adidas, Puma, Other\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "train_data_dir = 'data/train_original'\n",
    "validation_data_dir = 'data/validation_original'\n",
    "\n",
    "# Data preprocessing\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(input_shape[0], input_shape[1]),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(input_shape[0], input_shape[1]),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model definition\n",
    "original_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    # Conv2D(128, (3, 3), activation='relu'),\n",
    "    # MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "original_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = original_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size)\n",
    "\n",
    "# Save the model\n",
    "original_model.save('shoe_brand_classifier.h5')\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = original_model.evaluate(validation_generator, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model Design (Optimization Attempt #1) </br>\n",
    "- Adding 1 more Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.3868 - accuracy: 0.2812 - val_loss: 1.3510 - val_accuracy: 0.2812\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 1.5189 - accuracy: 0.1250 - val_loss: 1.3426 - val_accuracy: 0.3125\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 1.3734 - accuracy: 0.2500 - val_loss: 1.3551 - val_accuracy: 0.3438\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 1.3731 - accuracy: 0.3750 - val_loss: 1.3604 - val_accuracy: 0.3750\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 1.3554 - accuracy: 0.4062 - val_loss: 1.2989 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 1s 586ms/step - loss: 1.3170 - accuracy: 0.5000 - val_loss: 1.2463 - val_accuracy: 0.6250\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 1s 600ms/step - loss: 1.2775 - accuracy: 0.5312 - val_loss: 1.1333 - val_accuracy: 0.6875\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 1.1710 - accuracy: 0.5938 - val_loss: 1.0689 - val_accuracy: 0.6875\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 1.0290 - accuracy: 0.5000 - val_loss: 1.0277 - val_accuracy: 0.5938\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.9793 - accuracy: 0.6250 - val_loss: 0.8448 - val_accuracy: 0.7188\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 1.0071 - accuracy: 0.5625 - val_loss: 0.7172 - val_accuracy: 0.8438\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 0.7552 - accuracy: 0.7812 - val_loss: 0.7244 - val_accuracy: 0.8125\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 0.6663 - accuracy: 0.8438 - val_loss: 0.5214 - val_accuracy: 0.7812\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.8207 - accuracy: 0.6250 - val_loss: 1.3730 - val_accuracy: 0.4688\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 1.6635 - accuracy: 0.2500 - val_loss: 0.4222 - val_accuracy: 0.9062\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 0.4503 - accuracy: 0.9062 - val_loss: 0.6304 - val_accuracy: 0.7812\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.7294 - accuracy: 0.7812 - val_loss: 0.7986 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.3491 - accuracy: 0.8750 - val_loss: 0.8614 - val_accuracy: 0.6562\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.9843 - accuracy: 0.7500 - val_loss: 0.7837 - val_accuracy: 0.6875\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.5578 - accuracy: 0.8750 - val_loss: 0.7865 - val_accuracy: 0.6875\n",
      "2/2 - 0s - loss: 0.5452 - accuracy: 0.8250 - 220ms/epoch - 110ms/step\n",
      "\n",
      "Test accuracy: 0.824999988079071\n"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "optimization_model_1 = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimization_model_1.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = optimization_model_1.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size)\n",
    "\n",
    "# Save the model\n",
    "optimization_model_1.save('shoe_brand_classifier.h5')\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = original_model.evaluate(validation_generator, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model Design (Optimization Attempt #2) </br>\n",
    "- Adding 10 more images to each of the brands for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 83 images belonging to 4 classes.\n",
      "Found 80 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 3s 932ms/step - loss: 1.6058 - accuracy: 0.3137 - val_loss: 1.3737 - val_accuracy: 0.2500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 1s 482ms/step - loss: 1.3986 - accuracy: 0.2745 - val_loss: 1.3859 - val_accuracy: 0.2969\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 1s 589ms/step - loss: 1.3759 - accuracy: 0.3906 - val_loss: 1.3645 - val_accuracy: 0.3750\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 1s 588ms/step - loss: 1.3707 - accuracy: 0.3594 - val_loss: 1.3415 - val_accuracy: 0.4375\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 1s 659ms/step - loss: 1.3634 - accuracy: 0.2941 - val_loss: 1.3020 - val_accuracy: 0.4688\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 1s 480ms/step - loss: 1.2982 - accuracy: 0.4902 - val_loss: 1.2200 - val_accuracy: 0.6250\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 1s 489ms/step - loss: 1.1981 - accuracy: 0.6471 - val_loss: 1.1718 - val_accuracy: 0.4219\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 1s 482ms/step - loss: 1.2263 - accuracy: 0.3725 - val_loss: 1.0377 - val_accuracy: 0.5781\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 1s 486ms/step - loss: 1.0073 - accuracy: 0.5490 - val_loss: 1.0915 - val_accuracy: 0.5781\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 1s 515ms/step - loss: 1.1620 - accuracy: 0.5294 - val_loss: 0.9914 - val_accuracy: 0.5469\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 1s 576ms/step - loss: 0.9745 - accuracy: 0.5469 - val_loss: 0.8262 - val_accuracy: 0.6875\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 1s 620ms/step - loss: 0.8928 - accuracy: 0.6078 - val_loss: 0.8733 - val_accuracy: 0.6094\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 1s 589ms/step - loss: 0.7988 - accuracy: 0.6562 - val_loss: 0.7577 - val_accuracy: 0.7344\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 1s 506ms/step - loss: 0.7464 - accuracy: 0.7255 - val_loss: 0.7392 - val_accuracy: 0.7031\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 1s 483ms/step - loss: 0.7387 - accuracy: 0.6863 - val_loss: 0.5237 - val_accuracy: 0.8594\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 1s 482ms/step - loss: 0.5795 - accuracy: 0.8431 - val_loss: 0.5590 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 1s 630ms/step - loss: 0.4966 - accuracy: 0.8431 - val_loss: 0.4940 - val_accuracy: 0.8281\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 1s 493ms/step - loss: 0.4129 - accuracy: 0.9020 - val_loss: 0.4596 - val_accuracy: 0.8906\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 1s 616ms/step - loss: 0.4169 - accuracy: 0.9020 - val_loss: 0.5047 - val_accuracy: 0.8438\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 1s 495ms/step - loss: 0.6485 - accuracy: 0.7843 - val_loss: 0.3344 - val_accuracy: 0.8906\n",
      "3/3 - 0s - loss: 0.3141 - accuracy: 0.9000 - 374ms/epoch - 125ms/step\n",
      "\n",
      "Test accuracy: 0.8999999761581421\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = 'data/train_extend'\n",
    "validation_data_dir = 'data/validation_extend'\n",
    "\n",
    "# Data preprocessing\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(input_shape[0], input_shape[1]),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(input_shape[0], input_shape[1]),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model definition\n",
    "optimization_model_2 = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimization_model_2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = optimization_model_2.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size)\n",
    "\n",
    "# Save the model\n",
    "optimization_model_2.save('shoe_brand_classifier.h5')\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = optimization_model_2.evaluate(validation_generator, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 124ms/step\n",
      "Predicted Brand: Nike\n",
      "Confidence: 0.9603383\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('shoe_brand_classifier.h5')\n",
    "\n",
    "# Function to predict the brand of a given image\n",
    "def predict_brand(image_path):\n",
    "    img = image.load_img(image_path, target_size=(150, 150))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Convert to batch format (1, height, width, channels)\n",
    "    img_array /= 255.0  # Rescale pixel values to [0, 1]\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(img_array)\n",
    "\n",
    "    # return prediction \n",
    "    # Decode the prediction\n",
    "    brands = ['Adidas','Nike','Other','Puma' ]\n",
    "    predicted_brand = brands[np.argmax(prediction)]\n",
    "\n",
    "    # Print the prediction\n",
    "    print(\"Predicted Brand:\", predicted_brand)\n",
    "    print(\"Confidence:\", prediction[0][np.argmax(prediction)])\n",
    "\n",
    "# Test the model with a new image\n",
    "image_path = 'data/test/21.png' \n",
    "predict_brand(image_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
